{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GAN_oversample.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1m5AD72xiHvreWSf0E7_YHZrQ0EDbraM2","authorship_tag":"ABX9TyPay+hxi9fuNOt3BfXhbmAL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"PomF9YN0e0gR","executionInfo":{"status":"ok","timestamp":1622376539070,"user_tz":-120,"elapsed":358,"user":{"displayName":"Shirwan Piroti","photoUrl":"","userId":"12026415780371804948"}}},"source":["#Important Libraries\n","from zipfile import ZipFile\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","\n","#Data Encoding\n","from sklearn.preprocessing import  OneHotEncoder\n","\n","#Preprocessing\n","from sklearn.preprocessing import StandardScaler\n","\n","#Classifier\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"CFGZ1QzkfuxK","executionInfo":{"status":"ok","timestamp":1622377191710,"user_tz":-120,"elapsed":15019,"user":{"displayName":"Shirwan Piroti","photoUrl":"","userId":"12026415780371804948"}}},"source":["#Synthetic dataset\n","synth_train = pd.read_csv('/content/drive/MyDrive/Degree Project/train1.zip', delimiter=',')\n","synth_test = pd.read_csv('/content/drive/MyDrive/Degree Project/test1.zip', delimiter=',')\n","def data(df1,df2):\n","  Y1 = df1['Label'].to_numpy()                            #Labels\n","  Y2 = df1['Label'].to_numpy()\n","  X1 = df1.to_numpy()\n","  X2 = df2.to_numpy()\n","  n  = X1.shape[0]\n","  X = np.concatenate((X1,X2),axis=0)\n","  X = np.delete(X, -1, axis=1)\n","  X1 = X[:,[0,1,3,5]]                                    #Categorical Features\n","  X2 = X[:, [2,4,6]]                                     #Numerical Features\n","  X1 = OneHotEncoder().fit_transform(X1).toarray() #Encode categorical features\n","  X = np.concatenate((X1,X2), axis=1)\n","  X = StandardScaler().fit_transform(X)            #Standardizes data\n","  X = np.asarray(X).astype('float32')\n","  Y1 = np.asarray(Y1).astype('float32')\n","  Y2 = np.asarray(Y1).astype('float32')\n","  X1 = X[0:n]\n","  X2 = X[0:n]\n","  return X1,X2,Y1,Y2\n","X_train,X_test,Y_train,Y_test = data(synth_train,synth_test)\n","#X_train, Y_train = data(synth_train)\n","#X_test, Y_test = data(synth_test)"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"Domp7R6yfxLf"},"source":["#KDD-Cup 99 dataset\n","KDD_train = pd.read_csv('/content/drive/MyDrive/Degree Project/kddcup.data_10_percent.gz', compression='gzip').dropna() \n","KDD_test = pd.read_csv('/content/drive/MyDrive/Degree Project/corrected.gz', compression='gzip').dropna()\n","KDD_train.columns = [\n","    'duration',\n","    'protocol_type',\n","    'service',\n","    'flag',\n","    'src_bytes',\n","    'dst_bytes',\n","    'land',\n","    'wrong_fragment',\n","    'urgent',\n","    'hot',\n","    'num_failed_logins',\n","    'logged_in',\n","    'num_compromised',\n","    'root_shell',\n","    'su_attempted',\n","    'num_root',\n","    'num_file_creations',\n","    'num_shells',\n","    'num_access_files',\n","    'num_outbound_cmds',\n","    'is_host_login',\n","    'is_guest_login',\n","    'count',\n","    'srv_count',\n","    'serror_rate',\n","    'srv_serror_rate',\n","    'rerror_rate',\n","    'srv_rerror_rate',\n","    'same_srv_rate',\n","    'diff_srv_rate',\n","    'srv_diff_host_rate',\n","    'dst_host_count',\n","    'dst_host_srv_count',\n","    'dst_host_same_srv_rate',\n","    'dst_host_diff_srv_rate',\n","    'dst_host_same_src_port_rate',\n","    'dst_host_srv_diff_host_rate',\n","    'dst_host_serror_rate',\n","    'dst_host_srv_serror_rate',\n","    'dst_host_rerror_rate',\n","    'dst_host_srv_rerror_rate',\n","    'outcome'\n","]\n","\n","KDD_test.columns = KDD_train.columns\n","#Remove duplicates\n","KDD_train = KDD_train.drop_duplicates(keep=False)\n","KDD_test = KDD_test.drop_duplicates(keep=False)\n","#Change outcome to 0 if normal and 1 if anomalous\n","KDD_train['outcome'] = (KDD_train['outcome']!='normal.')*1\n","KDD_test['outcome'] = (KDD_test['outcome']!='normal.')*1\n","def data(df):\n","  X = df.to_numpy()\n","  Y = X[:,-1]\n","  X = np.delete(X, -1, axis=1)\n","  X1 = np.array([X[:,0]]).transpose()\n","  X2 = OneHotEncoder().fit_transform(X[:,1:2]).toarray()\n","  X3 = X[:,4:]\n","  X = np.concatenate((X1,X2,X3), axis=1)\n","  X = np.asarray(X).astype('float32')\n","  Y = np.asarray(Y).astype('float32')\n","  X = StandardScaler().fit_transform(X)\n","  normal_indx = np.where(Y==0)                      #Index of normal observations\n","  anomaly_indx = np.where(Y==1)                     #Index of anomalies\n","  X_normal  = X[normal_indx]\n","  X_anomaly = X[anomaly_indx]\n","  Y_normal  = Y[normal_indx]\n","  Y_anomaly = Y[anomaly_indx]\n","  return X,X_normal,X_anomaly,Y,Y_normal,Y_anomaly\n","\n","X_train,X_normal_train,X_anomaly_train,Y_train,Y_normal_train,Y_anomaly_train = data(KDD_train)\n","X_test,X_normal_test,X_anomaly_test,Y_test,Y_normal_test,Y_anomaly_test       = data(KDD_test) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iGfkghjsfzcD","executionInfo":{"status":"ok","timestamp":1622380240637,"user_tz":-120,"elapsed":316,"user":{"displayName":"Shirwan Piroti","photoUrl":"","userId":"12026415780371804948"}}},"source":["class GAN(keras.Model):\n","  def __init__(self,data_dim=34 ,latent_dim=20, init_kernel=keras.initializers.GlorotNormal, init_bias=keras.initializers.constant(0)):\n","    super(GAN, self).__init__()\n","    self.data_dim      = data_dim              #Dimension of data\n","    self.latent_dim    = latent_dim            #Dimension of latent space\n","    self.init_kernel   = init_kernel           #Inititialization of weights\n","    self.init_bias     = init_bias             #Inititialization of bias\n","    self.generator     = self.Generator()\n","    self.discriminator = self.Discriminator()\n","\n","  def Generator(self):\n","    generator_input  = keras.Input(self.latent_dim, name='z') #z\n","    generator        = layers.Dense(128, activation='relu', kernel_initializer=self.init_kernel, bias_initializer=self.init_bias)(generator_input)\n","    generator        = layers.Dense(256, activation='relu', kernel_initializer=self.init_kernel, bias_initializer=self.init_bias)(generator)\n","    generator        = layers.Dense(128, activation='relu', kernel_initializer=self.init_kernel, bias_initializer=self.init_bias)(generator)\n","    generator_output = layers.Dense(self.data_dim, activation='linear', kernel_initializer=self.init_kernel, bias_initializer=self.init_bias)(generator) #G(z)\n","    return keras.Model(generator_input, generator_output, name='Generator')\n","\n","  def Discriminator(self):\n","    D_input  = keras.Input(self.generator.output.shape[1])\n","    D  = layers.Dense(128, activation='relu', kernel_initializer=self.init_kernel, bias_initializer=self.init_bias)(D_input)\n","    D  = layers.Dense(256, activation='relu', kernel_initializer=self.init_kernel, bias_initializer=self.init_bias)(D)\n","    D  = layers.Dense(128, activation='relu', kernel_initializer=self.init_kernel, bias_initializer=self.init_bias)(D)\n","    D  = layers.Dense(64, activation='relu', kernel_initializer=self.init_kernel, bias_initializer=self.init_bias)(D)\n","    D_output = layers.Dense(1, activation='sigmoid', kernel_initializer=self.init_kernel, bias_initializer=self.init_bias)(D)\n","    return keras.Model(D_input, D_output, name='Discriminator')\n","\n","  def compile(self,optimizer = keras.optimizers.Adam(learning_rate=10**-5, beta_1=0.5), loss = keras.losses.BinaryCrossentropy(), train_metric = keras.metrics.BinaryCrossentropy):\n","    self.optimizer    = optimizer\n","    self.loss         = loss\n","\n","  def train(self,X_train,Epochs=50,batch_size=128):\n","      for Epoch in range(Epochs):\n","        X = tf.data.Dataset.from_tensor_slices(X_train)\n","        X = X.shuffle(buffer_size=1024).batch(batch_size) #Shuffles data and divides the dataset in batches\n","        pbar = tqdm(X, position=0, leave=True)            #Progressbar\n","        for step, x in enumerate(pbar):\n","          z = tf.random.normal(shape=(x.shape[0], self.latent_dim))     #Sample normal distributed noise\n","          with tf.GradientTape(persistent=True) as tape:\n","            x_ = self.generator(z)                                      #Generate x from noise              \n","            real_pred = self.discriminator(x)\n","            fake_pred = self.discriminator(x_)\n","            d_loss = self.loss(tf.ones_like(real_pred), real_pred)+self.loss(tf.zeros_like(fake_pred), fake_pred) #Discriminator loss\n","            g_loss = self.loss(tf.ones_like(fake_pred), fake_pred) #Generator loss\n","          \n","          d_gradients = tape.gradient(d_loss, self.discriminator.trainable_weights)               #Discriminator gradients\n","          self.optimizer.apply_gradients(zip(d_gradients, self.discriminator.trainable_weights))  #Update Discriminator paramaters\n","          g_gradients = tape.gradient(g_loss, self.generator.trainable_weights)                   #Generator & Encoder loss\n","          self.optimizer.apply_gradients(zip(g_gradients, self.generator.trainable_weights))      #Update Generator and Encoder parameters\n","          del tape\n","\n","          #Update progressbar\n","          if step % 100 == 0:\n","            pbar.set_description('Epoch %d of %d | D_loss=%.4f | G_loss=%.4f' % (Epoch+1, Epochs, d_loss, g_loss))\n","  \n","  def sample(self,N):\n","    z = tf.random.normal(shape=(N, self.latent_dim))     #Sample normal distributed noise\n","    x_ = self.generator(z)                               #Generate synthetic x from noise\n","    return x_"],"execution_count":61,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ggp_EvoZGNmw","executionInfo":{"status":"ok","timestamp":1622380410674,"user_tz":-120,"elapsed":103553,"user":{"displayName":"Shirwan Piroti","photoUrl":"","userId":"12026415780371804948"}},"outputId":"ef8b577d-2f34-401b-9356-2fe97e4dcde5"},"source":["GAN_sample = GAN(data_dim=X_train.shape[1])\n","GAN_sample.compile()\n","GAN_sample.train(X_train[10**6:],Epochs=200,batch_size=64)"],"execution_count":63,"outputs":[{"output_type":"stream","text":["Epoch 1 of 200 | D_loss=1.7234 | G_loss=0.8054: 100%|██████████| 12/12 [00:00<00:00, 26.86it/s]\n","Epoch 2 of 200 | D_loss=1.4059 | G_loss=0.7070: 100%|██████████| 12/12 [00:00<00:00, 30.89it/s]\n","Epoch 3 of 200 | D_loss=1.3019 | G_loss=0.6739: 100%|██████████| 12/12 [00:00<00:00, 28.95it/s]\n","Epoch 4 of 200 | D_loss=1.2010 | G_loss=0.6606: 100%|██████████| 12/12 [00:00<00:00, 19.10it/s]\n","Epoch 5 of 200 | D_loss=1.1470 | G_loss=0.6476: 100%|██████████| 12/12 [00:00<00:00, 18.98it/s]\n","Epoch 6 of 200 | D_loss=1.0941 | G_loss=0.6518: 100%|██████████| 12/12 [00:00<00:00, 30.18it/s]\n","Epoch 7 of 200 | D_loss=1.0975 | G_loss=0.6564: 100%|██████████| 12/12 [00:00<00:00, 19.07it/s]\n","Epoch 8 of 200 | D_loss=1.0526 | G_loss=0.6709: 100%|██████████| 12/12 [00:00<00:00, 30.25it/s]\n","Epoch 9 of 200 | D_loss=0.9842 | G_loss=0.6742: 100%|██████████| 12/12 [00:00<00:00, 19.08it/s]\n","Epoch 10 of 200 | D_loss=0.9888 | G_loss=0.6691: 100%|██████████| 12/12 [00:00<00:00, 19.09it/s]\n","Epoch 11 of 200 | D_loss=0.9836 | G_loss=0.6538: 100%|██████████| 12/12 [00:00<00:00, 28.78it/s]\n","Epoch 12 of 200 | D_loss=0.9909 | G_loss=0.6483: 100%|██████████| 12/12 [00:00<00:00, 29.69it/s]\n","Epoch 13 of 200 | D_loss=0.9945 | G_loss=0.6426: 100%|██████████| 12/12 [00:00<00:00, 29.26it/s]\n","Epoch 14 of 200 | D_loss=0.9801 | G_loss=0.6385: 100%|██████████| 12/12 [00:00<00:00, 30.15it/s]\n","Epoch 15 of 200 | D_loss=0.9783 | G_loss=0.6319: 100%|██████████| 12/12 [00:00<00:00, 29.76it/s]\n","Epoch 16 of 200 | D_loss=0.9755 | G_loss=0.6347: 100%|██████████| 12/12 [00:00<00:00, 19.07it/s]\n","Epoch 17 of 200 | D_loss=0.9566 | G_loss=0.6355: 100%|██████████| 12/12 [00:00<00:00, 28.51it/s]\n","Epoch 18 of 200 | D_loss=0.9438 | G_loss=0.6367: 100%|██████████| 12/12 [00:00<00:00, 19.05it/s]\n","Epoch 19 of 200 | D_loss=0.9251 | G_loss=0.6522: 100%|██████████| 12/12 [00:00<00:00, 19.06it/s]\n","Epoch 20 of 200 | D_loss=0.9538 | G_loss=0.6464: 100%|██████████| 12/12 [00:00<00:00, 30.41it/s]\n","Epoch 21 of 200 | D_loss=0.9153 | G_loss=0.6560: 100%|██████████| 12/12 [00:00<00:00, 26.97it/s]\n","Epoch 22 of 200 | D_loss=0.9450 | G_loss=0.6526: 100%|██████████| 12/12 [00:00<00:00, 19.10it/s]\n","Epoch 23 of 200 | D_loss=0.9014 | G_loss=0.6617: 100%|██████████| 12/12 [00:00<00:00, 19.08it/s]\n","Epoch 24 of 200 | D_loss=0.9083 | G_loss=0.6754: 100%|██████████| 12/12 [00:00<00:00, 30.28it/s]\n","Epoch 25 of 200 | D_loss=0.8583 | G_loss=0.6859: 100%|██████████| 12/12 [00:00<00:00, 19.00it/s]\n","Epoch 26 of 200 | D_loss=0.8871 | G_loss=0.6845: 100%|██████████| 12/12 [00:00<00:00, 29.60it/s]\n","Epoch 27 of 200 | D_loss=0.8829 | G_loss=0.6995: 100%|██████████| 12/12 [00:00<00:00, 30.13it/s]\n","Epoch 28 of 200 | D_loss=0.8432 | G_loss=0.7182: 100%|██████████| 12/12 [00:00<00:00, 30.25it/s]\n","Epoch 29 of 200 | D_loss=0.8222 | G_loss=0.7325: 100%|██████████| 12/12 [00:00<00:00, 19.12it/s]\n","Epoch 30 of 200 | D_loss=0.8244 | G_loss=0.7484: 100%|██████████| 12/12 [00:00<00:00, 19.11it/s]\n","Epoch 31 of 200 | D_loss=0.7930 | G_loss=0.7570: 100%|██████████| 12/12 [00:00<00:00, 30.16it/s]\n","Epoch 32 of 200 | D_loss=0.7993 | G_loss=0.7541: 100%|██████████| 12/12 [00:00<00:00, 19.12it/s]\n","Epoch 33 of 200 | D_loss=0.8248 | G_loss=0.7409: 100%|██████████| 12/12 [00:00<00:00, 19.07it/s]\n","Epoch 34 of 200 | D_loss=0.8318 | G_loss=0.7196: 100%|██████████| 12/12 [00:00<00:00, 29.08it/s]\n","Epoch 35 of 200 | D_loss=0.8619 | G_loss=0.7074: 100%|██████████| 12/12 [00:00<00:00, 19.06it/s]\n","Epoch 36 of 200 | D_loss=0.8720 | G_loss=0.7010: 100%|██████████| 12/12 [00:00<00:00, 19.12it/s]\n","Epoch 37 of 200 | D_loss=0.8887 | G_loss=0.6784: 100%|██████████| 12/12 [00:00<00:00, 19.05it/s]\n","Epoch 38 of 200 | D_loss=0.9006 | G_loss=0.6730: 100%|██████████| 12/12 [00:00<00:00, 31.14it/s]\n","Epoch 39 of 200 | D_loss=0.9136 | G_loss=0.6708: 100%|██████████| 12/12 [00:00<00:00, 19.03it/s]\n","Epoch 40 of 200 | D_loss=0.8654 | G_loss=0.7009: 100%|██████████| 12/12 [00:00<00:00, 28.64it/s]\n","Epoch 41 of 200 | D_loss=0.8940 | G_loss=0.6902: 100%|██████████| 12/12 [00:00<00:00, 18.82it/s]\n","Epoch 42 of 200 | D_loss=0.8877 | G_loss=0.6870: 100%|██████████| 12/12 [00:00<00:00, 29.28it/s]\n","Epoch 43 of 200 | D_loss=0.8417 | G_loss=0.7016: 100%|██████████| 12/12 [00:00<00:00, 30.19it/s]\n","Epoch 44 of 200 | D_loss=0.8787 | G_loss=0.7058: 100%|██████████| 12/12 [00:00<00:00, 19.02it/s]\n","Epoch 45 of 200 | D_loss=0.8626 | G_loss=0.7207: 100%|██████████| 12/12 [00:00<00:00, 19.09it/s]\n","Epoch 46 of 200 | D_loss=0.8392 | G_loss=0.7355: 100%|██████████| 12/12 [00:00<00:00, 31.05it/s]\n","Epoch 47 of 200 | D_loss=0.8598 | G_loss=0.7632: 100%|██████████| 12/12 [00:00<00:00, 18.85it/s]\n","Epoch 48 of 200 | D_loss=0.7834 | G_loss=0.7941: 100%|██████████| 12/12 [00:00<00:00, 27.76it/s]\n","Epoch 49 of 200 | D_loss=0.7957 | G_loss=0.8094: 100%|██████████| 12/12 [00:00<00:00, 19.10it/s]\n","Epoch 50 of 200 | D_loss=0.8011 | G_loss=0.8115: 100%|██████████| 12/12 [00:00<00:00, 30.78it/s]\n","Epoch 51 of 200 | D_loss=0.7940 | G_loss=0.7840: 100%|██████████| 12/12 [00:00<00:00, 18.99it/s]\n","Epoch 52 of 200 | D_loss=0.7794 | G_loss=0.8048: 100%|██████████| 12/12 [00:00<00:00, 19.11it/s]\n","Epoch 53 of 200 | D_loss=0.7659 | G_loss=0.8214: 100%|██████████| 12/12 [00:00<00:00, 29.00it/s]\n","Epoch 54 of 200 | D_loss=0.8249 | G_loss=0.7754: 100%|██████████| 12/12 [00:00<00:00, 19.03it/s]\n","Epoch 55 of 200 | D_loss=0.8395 | G_loss=0.7521: 100%|██████████| 12/12 [00:00<00:00, 29.64it/s]\n","Epoch 56 of 200 | D_loss=0.8310 | G_loss=0.7566: 100%|██████████| 12/12 [00:00<00:00, 29.17it/s]\n","Epoch 57 of 200 | D_loss=0.8500 | G_loss=0.7524: 100%|██████████| 12/12 [00:00<00:00, 29.70it/s]\n","Epoch 58 of 200 | D_loss=0.8637 | G_loss=0.7663: 100%|██████████| 12/12 [00:00<00:00, 28.05it/s]\n","Epoch 59 of 200 | D_loss=0.8583 | G_loss=0.7416: 100%|██████████| 12/12 [00:00<00:00, 28.19it/s]\n","Epoch 60 of 200 | D_loss=0.8252 | G_loss=0.7772: 100%|██████████| 12/12 [00:00<00:00, 19.11it/s]\n","Epoch 61 of 200 | D_loss=0.8176 | G_loss=0.7754: 100%|██████████| 12/12 [00:00<00:00, 28.64it/s]\n","Epoch 62 of 200 | D_loss=0.7999 | G_loss=0.7824: 100%|██████████| 12/12 [00:00<00:00, 28.24it/s]\n","Epoch 63 of 200 | D_loss=0.8101 | G_loss=0.7812: 100%|██████████| 12/12 [00:00<00:00, 19.11it/s]\n","Epoch 64 of 200 | D_loss=0.8086 | G_loss=0.7590: 100%|██████████| 12/12 [00:00<00:00, 29.46it/s]\n","Epoch 65 of 200 | D_loss=0.8060 | G_loss=0.7997: 100%|██████████| 12/12 [00:00<00:00, 29.66it/s]\n","Epoch 66 of 200 | D_loss=0.8127 | G_loss=0.7634: 100%|██████████| 12/12 [00:00<00:00, 18.98it/s]\n","Epoch 67 of 200 | D_loss=0.7810 | G_loss=0.8009: 100%|██████████| 12/12 [00:00<00:00, 19.05it/s]\n","Epoch 68 of 200 | D_loss=0.8050 | G_loss=0.7989: 100%|██████████| 12/12 [00:00<00:00, 19.04it/s]\n","Epoch 69 of 200 | D_loss=0.7849 | G_loss=0.8168: 100%|██████████| 12/12 [00:00<00:00, 29.47it/s]\n","Epoch 70 of 200 | D_loss=0.7469 | G_loss=0.8575: 100%|██████████| 12/12 [00:00<00:00, 19.14it/s]\n","Epoch 71 of 200 | D_loss=0.7638 | G_loss=0.8672: 100%|██████████| 12/12 [00:00<00:00, 19.11it/s]\n","Epoch 72 of 200 | D_loss=0.7294 | G_loss=0.8801: 100%|██████████| 12/12 [00:00<00:00, 19.09it/s]\n","Epoch 73 of 200 | D_loss=0.7085 | G_loss=0.9141: 100%|██████████| 12/12 [00:00<00:00, 30.65it/s]\n","Epoch 74 of 200 | D_loss=0.6863 | G_loss=0.9355: 100%|██████████| 12/12 [00:00<00:00, 28.47it/s]\n","Epoch 75 of 200 | D_loss=0.6428 | G_loss=1.0001: 100%|██████████| 12/12 [00:00<00:00, 29.70it/s]\n","Epoch 76 of 200 | D_loss=0.6468 | G_loss=0.9886: 100%|██████████| 12/12 [00:00<00:00, 19.14it/s]\n","Epoch 77 of 200 | D_loss=0.6222 | G_loss=1.0280: 100%|██████████| 12/12 [00:00<00:00, 30.27it/s]\n","Epoch 78 of 200 | D_loss=0.6275 | G_loss=0.9964: 100%|██████████| 12/12 [00:00<00:00, 30.28it/s]\n","Epoch 79 of 200 | D_loss=0.6398 | G_loss=1.0048: 100%|██████████| 12/12 [00:00<00:00, 18.96it/s]\n","Epoch 80 of 200 | D_loss=0.6590 | G_loss=0.9969: 100%|██████████| 12/12 [00:00<00:00, 19.11it/s]\n","Epoch 81 of 200 | D_loss=0.6168 | G_loss=1.0075: 100%|██████████| 12/12 [00:00<00:00, 19.04it/s]\n","Epoch 82 of 200 | D_loss=0.6135 | G_loss=1.0142: 100%|██████████| 12/12 [00:00<00:00, 19.06it/s]\n","Epoch 83 of 200 | D_loss=0.6503 | G_loss=1.0348: 100%|██████████| 12/12 [00:00<00:00, 19.12it/s]\n","Epoch 84 of 200 | D_loss=0.6152 | G_loss=0.9861: 100%|██████████| 12/12 [00:00<00:00, 30.68it/s]\n","Epoch 85 of 200 | D_loss=0.6505 | G_loss=0.9734: 100%|██████████| 12/12 [00:00<00:00, 19.01it/s]\n","Epoch 86 of 200 | D_loss=0.6900 | G_loss=0.9512: 100%|██████████| 12/12 [00:00<00:00, 29.48it/s]\n","Epoch 87 of 200 | D_loss=0.7376 | G_loss=0.9489: 100%|██████████| 12/12 [00:00<00:00, 19.07it/s]\n","Epoch 88 of 200 | D_loss=0.7315 | G_loss=0.8894: 100%|██████████| 12/12 [00:00<00:00, 29.63it/s]\n","Epoch 89 of 200 | D_loss=0.6999 | G_loss=0.8685: 100%|██████████| 12/12 [00:00<00:00, 29.48it/s]\n","Epoch 90 of 200 | D_loss=0.7517 | G_loss=0.8714: 100%|██████████| 12/12 [00:00<00:00, 19.08it/s]\n","Epoch 91 of 200 | D_loss=0.8218 | G_loss=0.8118: 100%|██████████| 12/12 [00:00<00:00, 27.83it/s]\n","Epoch 92 of 200 | D_loss=0.8887 | G_loss=0.7455: 100%|██████████| 12/12 [00:00<00:00, 19.09it/s]\n","Epoch 93 of 200 | D_loss=0.8427 | G_loss=0.7713: 100%|██████████| 12/12 [00:00<00:00, 28.47it/s]\n","Epoch 94 of 200 | D_loss=0.9713 | G_loss=0.7364: 100%|██████████| 12/12 [00:00<00:00, 26.72it/s]\n","Epoch 95 of 200 | D_loss=0.9626 | G_loss=0.7333: 100%|██████████| 12/12 [00:00<00:00, 18.89it/s]\n","Epoch 96 of 200 | D_loss=0.9075 | G_loss=0.7654: 100%|██████████| 12/12 [00:00<00:00, 19.03it/s]\n","Epoch 97 of 200 | D_loss=0.9225 | G_loss=0.7964: 100%|██████████| 12/12 [00:00<00:00, 19.02it/s]\n","Epoch 98 of 200 | D_loss=0.8661 | G_loss=0.8380: 100%|██████████| 12/12 [00:00<00:00, 19.02it/s]\n","Epoch 99 of 200 | D_loss=0.7641 | G_loss=0.8939: 100%|██████████| 12/12 [00:00<00:00, 19.13it/s]\n","Epoch 100 of 200 | D_loss=0.7112 | G_loss=0.9600: 100%|██████████| 12/12 [00:00<00:00, 28.40it/s]\n","Epoch 101 of 200 | D_loss=0.7222 | G_loss=1.0608: 100%|██████████| 12/12 [00:00<00:00, 30.01it/s]\n","Epoch 102 of 200 | D_loss=0.6655 | G_loss=1.0726: 100%|██████████| 12/12 [00:00<00:00, 29.67it/s]\n","Epoch 103 of 200 | D_loss=0.6566 | G_loss=1.0925: 100%|██████████| 12/12 [00:00<00:00, 29.81it/s]\n","Epoch 104 of 200 | D_loss=0.6471 | G_loss=1.1336: 100%|██████████| 12/12 [00:00<00:00, 29.64it/s]\n","Epoch 105 of 200 | D_loss=0.6306 | G_loss=1.1522: 100%|██████████| 12/12 [00:00<00:00, 28.64it/s]\n","Epoch 106 of 200 | D_loss=0.6086 | G_loss=1.1565: 100%|██████████| 12/12 [00:00<00:00, 29.89it/s]\n","Epoch 107 of 200 | D_loss=0.6205 | G_loss=1.1958: 100%|██████████| 12/12 [00:00<00:00, 30.11it/s]\n","Epoch 108 of 200 | D_loss=0.6691 | G_loss=1.0844: 100%|██████████| 12/12 [00:00<00:00, 19.14it/s]\n","Epoch 109 of 200 | D_loss=0.6125 | G_loss=1.0928: 100%|██████████| 12/12 [00:00<00:00, 26.85it/s]\n","Epoch 110 of 200 | D_loss=0.6531 | G_loss=1.0568: 100%|██████████| 12/12 [00:00<00:00, 19.05it/s]\n","Epoch 111 of 200 | D_loss=0.7145 | G_loss=1.0299: 100%|██████████| 12/12 [00:00<00:00, 28.74it/s]\n","Epoch 112 of 200 | D_loss=0.6095 | G_loss=1.0576: 100%|██████████| 12/12 [00:00<00:00, 29.06it/s]\n","Epoch 113 of 200 | D_loss=0.6077 | G_loss=1.0374: 100%|██████████| 12/12 [00:00<00:00, 29.36it/s]\n","Epoch 114 of 200 | D_loss=0.6476 | G_loss=1.0920: 100%|██████████| 12/12 [00:00<00:00, 28.90it/s]\n","Epoch 115 of 200 | D_loss=0.6102 | G_loss=1.0712: 100%|██████████| 12/12 [00:00<00:00, 28.00it/s]\n","Epoch 116 of 200 | D_loss=0.6417 | G_loss=1.0804: 100%|██████████| 12/12 [00:00<00:00, 18.92it/s]\n","Epoch 117 of 200 | D_loss=0.6305 | G_loss=1.0913: 100%|██████████| 12/12 [00:00<00:00, 29.66it/s]\n","Epoch 118 of 200 | D_loss=0.6184 | G_loss=1.0958: 100%|██████████| 12/12 [00:00<00:00, 28.77it/s]\n","Epoch 119 of 200 | D_loss=0.7375 | G_loss=1.0901: 100%|██████████| 12/12 [00:00<00:00, 28.81it/s]\n","Epoch 120 of 200 | D_loss=0.6472 | G_loss=1.0809: 100%|██████████| 12/12 [00:00<00:00, 19.10it/s]\n","Epoch 121 of 200 | D_loss=0.6658 | G_loss=1.0818: 100%|██████████| 12/12 [00:00<00:00, 19.09it/s]\n","Epoch 122 of 200 | D_loss=0.5524 | G_loss=1.0930: 100%|██████████| 12/12 [00:00<00:00, 19.10it/s]\n","Epoch 123 of 200 | D_loss=0.6360 | G_loss=1.0493: 100%|██████████| 12/12 [00:00<00:00, 19.05it/s]\n","Epoch 124 of 200 | D_loss=0.6501 | G_loss=1.0710: 100%|██████████| 12/12 [00:00<00:00, 29.26it/s]\n","Epoch 125 of 200 | D_loss=0.6358 | G_loss=1.0474: 100%|██████████| 12/12 [00:00<00:00, 19.04it/s]\n","Epoch 126 of 200 | D_loss=0.6073 | G_loss=1.0571: 100%|██████████| 12/12 [00:00<00:00, 28.79it/s]\n","Epoch 127 of 200 | D_loss=0.6635 | G_loss=1.0270: 100%|██████████| 12/12 [00:00<00:00, 19.02it/s]\n","Epoch 128 of 200 | D_loss=0.7011 | G_loss=0.9905: 100%|██████████| 12/12 [00:00<00:00, 19.10it/s]\n","Epoch 129 of 200 | D_loss=0.6415 | G_loss=0.9628: 100%|██████████| 12/12 [00:00<00:00, 19.06it/s]\n","Epoch 130 of 200 | D_loss=0.6867 | G_loss=0.9492: 100%|██████████| 12/12 [00:00<00:00, 19.06it/s]\n","Epoch 131 of 200 | D_loss=0.6163 | G_loss=0.9657: 100%|██████████| 12/12 [00:00<00:00, 19.08it/s]\n","Epoch 132 of 200 | D_loss=0.7309 | G_loss=0.9581: 100%|██████████| 12/12 [00:00<00:00, 19.06it/s]\n","Epoch 133 of 200 | D_loss=0.7766 | G_loss=0.9126: 100%|██████████| 12/12 [00:00<00:00, 20.54it/s]\n","Epoch 134 of 200 | D_loss=0.7183 | G_loss=0.9377: 100%|██████████| 12/12 [00:00<00:00, 19.05it/s]\n","Epoch 135 of 200 | D_loss=0.6470 | G_loss=0.9909: 100%|██████████| 12/12 [00:00<00:00, 30.30it/s]\n","Epoch 136 of 200 | D_loss=0.7613 | G_loss=0.9620: 100%|██████████| 12/12 [00:00<00:00, 19.06it/s]\n","Epoch 137 of 200 | D_loss=0.7876 | G_loss=0.9576: 100%|██████████| 12/12 [00:00<00:00, 29.70it/s]\n","Epoch 138 of 200 | D_loss=0.7495 | G_loss=0.9551: 100%|██████████| 12/12 [00:00<00:00, 26.97it/s]\n","Epoch 139 of 200 | D_loss=0.7078 | G_loss=0.9970: 100%|██████████| 12/12 [00:00<00:00, 29.25it/s]\n","Epoch 140 of 200 | D_loss=0.7907 | G_loss=0.9871: 100%|██████████| 12/12 [00:00<00:00, 19.15it/s]\n","Epoch 141 of 200 | D_loss=0.6740 | G_loss=1.0527: 100%|██████████| 12/12 [00:00<00:00, 30.32it/s]\n","Epoch 142 of 200 | D_loss=0.7685 | G_loss=0.9592: 100%|██████████| 12/12 [00:00<00:00, 29.26it/s]\n","Epoch 143 of 200 | D_loss=0.6122 | G_loss=1.0665: 100%|██████████| 12/12 [00:00<00:00, 29.35it/s]\n","Epoch 144 of 200 | D_loss=0.6557 | G_loss=1.0220: 100%|██████████| 12/12 [00:00<00:00, 19.07it/s]\n","Epoch 145 of 200 | D_loss=0.7098 | G_loss=1.0026: 100%|██████████| 12/12 [00:00<00:00, 27.68it/s]\n","Epoch 146 of 200 | D_loss=0.7007 | G_loss=1.0225: 100%|██████████| 12/12 [00:00<00:00, 19.12it/s]\n","Epoch 147 of 200 | D_loss=0.5618 | G_loss=1.1454: 100%|██████████| 12/12 [00:00<00:00, 19.01it/s]\n","Epoch 148 of 200 | D_loss=0.6396 | G_loss=1.1563: 100%|██████████| 12/12 [00:00<00:00, 28.27it/s]\n","Epoch 149 of 200 | D_loss=0.6491 | G_loss=1.1667: 100%|██████████| 12/12 [00:00<00:00, 30.16it/s]\n","Epoch 150 of 200 | D_loss=0.5388 | G_loss=1.1911: 100%|██████████| 12/12 [00:00<00:00, 18.94it/s]\n","Epoch 151 of 200 | D_loss=0.5711 | G_loss=1.2624: 100%|██████████| 12/12 [00:00<00:00, 25.46it/s]\n","Epoch 152 of 200 | D_loss=0.5359 | G_loss=1.2619: 100%|██████████| 12/12 [00:00<00:00, 29.17it/s]\n","Epoch 153 of 200 | D_loss=0.5571 | G_loss=1.2977: 100%|██████████| 12/12 [00:00<00:00, 28.62it/s]\n","Epoch 154 of 200 | D_loss=0.5090 | G_loss=1.3496: 100%|██████████| 12/12 [00:00<00:00, 19.05it/s]\n","Epoch 155 of 200 | D_loss=0.4590 | G_loss=1.3736: 100%|██████████| 12/12 [00:00<00:00, 18.90it/s]\n","Epoch 156 of 200 | D_loss=0.4357 | G_loss=1.3818: 100%|██████████| 12/12 [00:00<00:00, 19.04it/s]\n","Epoch 157 of 200 | D_loss=0.5236 | G_loss=1.3273: 100%|██████████| 12/12 [00:00<00:00, 29.54it/s]\n","Epoch 158 of 200 | D_loss=0.5243 | G_loss=1.3344: 100%|██████████| 12/12 [00:00<00:00, 28.79it/s]\n","Epoch 159 of 200 | D_loss=0.5131 | G_loss=1.3035: 100%|██████████| 12/12 [00:00<00:00, 18.91it/s]\n","Epoch 160 of 200 | D_loss=0.4439 | G_loss=1.3111: 100%|██████████| 12/12 [00:00<00:00, 28.61it/s]\n","Epoch 161 of 200 | D_loss=0.5075 | G_loss=1.2251: 100%|██████████| 12/12 [00:00<00:00, 18.90it/s]\n","Epoch 162 of 200 | D_loss=0.5340 | G_loss=1.2751: 100%|██████████| 12/12 [00:00<00:00, 28.89it/s]\n","Epoch 163 of 200 | D_loss=0.5329 | G_loss=1.2111: 100%|██████████| 12/12 [00:00<00:00, 19.06it/s]\n","Epoch 164 of 200 | D_loss=0.6093 | G_loss=1.2181: 100%|██████████| 12/12 [00:00<00:00, 19.07it/s]\n","Epoch 165 of 200 | D_loss=0.6118 | G_loss=1.1284: 100%|██████████| 12/12 [00:00<00:00, 19.03it/s]\n","Epoch 166 of 200 | D_loss=0.5974 | G_loss=1.1362: 100%|██████████| 12/12 [00:00<00:00, 30.05it/s]\n","Epoch 167 of 200 | D_loss=0.6531 | G_loss=1.1366: 100%|██████████| 12/12 [00:00<00:00, 24.62it/s]\n","Epoch 168 of 200 | D_loss=0.5907 | G_loss=1.1574: 100%|██████████| 12/12 [00:00<00:00, 30.33it/s]\n","Epoch 169 of 200 | D_loss=0.5307 | G_loss=1.1701: 100%|██████████| 12/12 [00:00<00:00, 28.44it/s]\n","Epoch 170 of 200 | D_loss=0.6452 | G_loss=1.1872: 100%|██████████| 12/12 [00:00<00:00, 29.10it/s]\n","Epoch 171 of 200 | D_loss=0.7383 | G_loss=1.1262: 100%|██████████| 12/12 [00:00<00:00, 28.48it/s]\n","Epoch 172 of 200 | D_loss=0.7095 | G_loss=1.1669: 100%|██████████| 12/12 [00:00<00:00, 29.25it/s]\n","Epoch 173 of 200 | D_loss=0.5736 | G_loss=1.2192: 100%|██████████| 12/12 [00:00<00:00, 28.85it/s]\n","Epoch 174 of 200 | D_loss=0.6601 | G_loss=1.1922: 100%|██████████| 12/12 [00:00<00:00, 26.72it/s]\n","Epoch 175 of 200 | D_loss=0.5695 | G_loss=1.2690: 100%|██████████| 12/12 [00:00<00:00, 19.08it/s]\n","Epoch 176 of 200 | D_loss=0.5583 | G_loss=1.3213: 100%|██████████| 12/12 [00:00<00:00, 28.48it/s]\n","Epoch 177 of 200 | D_loss=0.5547 | G_loss=1.2962: 100%|██████████| 12/12 [00:00<00:00, 19.10it/s]\n","Epoch 178 of 200 | D_loss=0.5902 | G_loss=1.3201: 100%|██████████| 12/12 [00:00<00:00, 28.95it/s]\n","Epoch 179 of 200 | D_loss=0.4780 | G_loss=1.3603: 100%|██████████| 12/12 [00:00<00:00, 27.22it/s]\n","Epoch 180 of 200 | D_loss=0.5113 | G_loss=1.3963: 100%|██████████| 12/12 [00:00<00:00, 29.23it/s]\n","Epoch 181 of 200 | D_loss=0.4864 | G_loss=1.4478: 100%|██████████| 12/12 [00:00<00:00, 19.14it/s]\n","Epoch 182 of 200 | D_loss=0.4947 | G_loss=1.4565: 100%|██████████| 12/12 [00:00<00:00, 29.00it/s]\n","Epoch 183 of 200 | D_loss=0.4279 | G_loss=1.4581: 100%|██████████| 12/12 [00:00<00:00, 29.23it/s]\n","Epoch 184 of 200 | D_loss=0.5145 | G_loss=1.3713: 100%|██████████| 12/12 [00:00<00:00, 28.55it/s]\n","Epoch 185 of 200 | D_loss=0.5004 | G_loss=1.3646: 100%|██████████| 12/12 [00:00<00:00, 27.90it/s]\n","Epoch 186 of 200 | D_loss=0.5831 | G_loss=1.3615: 100%|██████████| 12/12 [00:00<00:00, 29.68it/s]\n","Epoch 187 of 200 | D_loss=0.4927 | G_loss=1.3796: 100%|██████████| 12/12 [00:00<00:00, 27.73it/s]\n","Epoch 188 of 200 | D_loss=0.5170 | G_loss=1.3393: 100%|██████████| 12/12 [00:00<00:00, 29.76it/s]\n","Epoch 189 of 200 | D_loss=0.5457 | G_loss=1.3114: 100%|██████████| 12/12 [00:00<00:00, 18.91it/s]\n","Epoch 190 of 200 | D_loss=0.5408 | G_loss=1.3264: 100%|██████████| 12/12 [00:00<00:00, 29.57it/s]\n","Epoch 191 of 200 | D_loss=0.5515 | G_loss=1.4211: 100%|██████████| 12/12 [00:00<00:00, 28.29it/s]\n","Epoch 192 of 200 | D_loss=0.4704 | G_loss=1.4013: 100%|██████████| 12/12 [00:00<00:00, 29.03it/s]\n","Epoch 193 of 200 | D_loss=0.4695 | G_loss=1.3880: 100%|██████████| 12/12 [00:00<00:00, 28.73it/s]\n","Epoch 194 of 200 | D_loss=0.5921 | G_loss=1.3466: 100%|██████████| 12/12 [00:00<00:00, 18.97it/s]\n","Epoch 195 of 200 | D_loss=0.6317 | G_loss=1.2491: 100%|██████████| 12/12 [00:00<00:00, 29.84it/s]\n","Epoch 196 of 200 | D_loss=0.5354 | G_loss=1.4467: 100%|██████████| 12/12 [00:00<00:00, 18.80it/s]\n","Epoch 197 of 200 | D_loss=0.5727 | G_loss=1.3485: 100%|██████████| 12/12 [00:00<00:00, 18.92it/s]\n","Epoch 198 of 200 | D_loss=0.5870 | G_loss=1.3626: 100%|██████████| 12/12 [00:00<00:00, 28.86it/s]\n","Epoch 199 of 200 | D_loss=0.5783 | G_loss=1.3573: 100%|██████████| 12/12 [00:00<00:00, 26.58it/s]\n","Epoch 200 of 200 | D_loss=0.5683 | G_loss=1.3123: 100%|██████████| 12/12 [00:00<00:00, 27.83it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"MxKnSH5kSZfj","executionInfo":{"status":"ok","timestamp":1622378547906,"user_tz":-120,"elapsed":193,"user":{"displayName":"Shirwan Piroti","photoUrl":"","userId":"12026415780371804948"}}},"source":["X_ = GAN_sample.sample(10)"],"execution_count":55,"outputs":[]}]}